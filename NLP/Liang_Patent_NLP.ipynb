{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1627963225113,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "_0w9VNeu7Snu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1627963225405,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "BwAv0VkH8Q0e",
    "outputId": "d8c54685-7334-4242-e246-1d10298eb3ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_text</th>\n",
       "      <th>patent_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RE30525</td>\n",
       "      <td>Extended range hydraulic transmission</td>\n",
       "      <td>Claims (1)\\nHide Dependent \\nI claim. 1. An ex...</td>\n",
       "      <td>['said', 'means', 'hydraulic', 'shaft', 'outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RE30135</td>\n",
       "      <td>Electric fail-safe actuator</td>\n",
       "      <td>Claims (13)\\nHide Dependent \\nI claim: .[.1. A...</td>\n",
       "      <td>['electric', 'said', 'motor', 'valve', 'actuat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RE29872</td>\n",
       "      <td>Differential gear mechanism</td>\n",
       "      <td>Claims (13)\\nHide Dependent \\nWhat is claimed ...</td>\n",
       "      <td>['said', 'cam', 'cam member', 'differential ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RE30334</td>\n",
       "      <td>Pressure compensated hermetically sealed trans...</td>\n",
       "      <td>Claims (15)\\nHide Dependent \\nWhat is claimed ...</td>\n",
       "      <td>['transmission means', 'said', 'environment', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RE30120</td>\n",
       "      <td>Lobe type pump adjustment</td>\n",
       "      <td>Claims (2)\\nHide Dependent \\nI claim: .[.1. A ...</td>\n",
       "      <td>['hub', 'said', 'abutment', 'shaft', 'spring',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number  ...                                    patent_keywords\n",
       "0       RE30525  ...  ['said', 'means', 'hydraulic', 'shaft', 'outpu...\n",
       "1       RE30135  ...  ['electric', 'said', 'motor', 'valve', 'actuat...\n",
       "2       RE29872  ...  ['said', 'cam', 'cam member', 'differential ge...\n",
       "3       RE30334  ...  ['transmission means', 'said', 'environment', ...\n",
       "4       RE30120  ...  ['hub', 'said', 'abutment', 'shaft', 'spring',...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mechanism_nlp_complete_withkeywords.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1627963225406,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "k__kwFqq_O7T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627963225407,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "yn7gCHWr_O-P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627963225407,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "R7w9PyeR8At0"
   },
   "outputs": [],
   "source": [
    "keywords = df[\"patent_keywords\"].map(yaml.safe_load).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1627963225516,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "cOwfelSm8XJr",
    "outputId": "1f9ee654-9944-4893-c695-588df54a2d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  3 04:00:25 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    35W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2705,
     "status": "ok",
     "timestamp": 1627963228219,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "osubOMZ38dSr",
    "outputId": "c458709e-fd57-4806-a22b-582682ab8422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 7.4 ms, total: 33.5 ms\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2575,
     "status": "ok",
     "timestamp": 1627963230790,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "91wlRSUm8dVO",
    "outputId": "f8388740-e652-4fcd-8a45-7921cfc461df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "from itertools import compress\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
    "                         AdamW, get_linear_schedule_with_warmup, \\\n",
    "                         TrainingArguments, BeamScorer, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
    "                             RandomSampler, SequentialSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627963230790,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "cxkZr3SP8dX_"
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "DEBUG           = False\n",
    "\n",
    "INPUT_DIR       = 'articles'\n",
    "\n",
    "USE_APEX        = True\n",
    "APEX_OPT_LEVEL  = 'O1'\n",
    "\n",
    "MODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n",
    "\n",
    "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "                    \n",
    "MAXLEN          = 768  #{768, 1024, 1280, 1600}\n",
    "\n",
    "TRAIN_SIZE      = 0.8\n",
    "\n",
    "if USE_APEX:\n",
    "    TRAIN_BATCHSIZE = 4\n",
    "    BATCH_UPDATE    = 8\n",
    "else:\n",
    "    TRAIN_BATCHSIZE = 2\n",
    "    BATCH_UPDATE    = 32\n",
    "# EPOCHS          = 10!!!!!50 100 \n",
    "EPOCHS          = 20\n",
    "LR              = 5e-3\n",
    "EPS             = 1e-8\n",
    "WARMUP_STEPS    = 1e2\n",
    "\n",
    "SEED            = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627963230790,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "a8uJsZp78dak"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627963230791,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "jVZk1D8i9AU_",
    "outputId": "c72f3748-ee65-4497-8a88-f2cc19b2631d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 50\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "for patent_number, patent_title, patent_text, patent_keywords in df.itertuples(index=False):\n",
    "    data[patent_number]=[patent_title, patent_text, yaml.safe_load(patent_keywords)] \n",
    "\n",
    "\n",
    "print(f\"Number of articles: {len(data) :,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1627963230791,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "qius0KcU-bRj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1627963230971,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "lHVJREdW-bVd",
    "outputId": "7f5be92d-f703-4ce0-8bb3-65e3b5a5e25e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'means',\n",
       " 'hydraulic',\n",
       " 'shaft',\n",
       " 'output',\n",
       " 'intermediate shaft',\n",
       " 'input',\n",
       " 'planetary gearing',\n",
       " 'planetary',\n",
       " 'hydraulic elements',\n",
       " 'gearing',\n",
       " 'input shaft',\n",
       " 'disengageable']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( data.get('RE30525')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1627963230972,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "ZIN5vilJ9DNa",
    "outputId": "6dd59700-3e99-481f-c07d-5f5325e40492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique keywords: 440\n",
      "CPU times: user 624 µs, sys: 0 ns, total: 624 µs\n",
      "Wall time: 542 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_keywords = set()\n",
    "for v in keywords:\n",
    "    for w in v:\n",
    "        all_keywords.add(w)\n",
    "\n",
    "\n",
    "print(f\"Number of unique keywords: {len(all_keywords) :,}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963230973,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "spP5un1X9DRG"
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, randomize=True):\n",
    "\n",
    "        title, text, keywords = [], [], []\n",
    "#       title, text, keywords can be cat, dog, elephant \n",
    "        for k, v in data.items():\n",
    "            title.append(v[0])\n",
    "            text.append(v[1])\n",
    "            keywords.append(v[2])\n",
    "\n",
    "        self.randomize = randomize\n",
    "        self.tokenizer = tokenizer \n",
    "        self.title     = title\n",
    "        self.text      = text\n",
    "        self.keywords  = keywords  \n",
    "\n",
    "    #---------------------------------------------#\n",
    "\n",
    "    @staticmethod\n",
    "    def join_keywords(keywords, randomize=True):\n",
    "        N = len(keywords)\n",
    "\n",
    "        #random sampling and shuffle\n",
    "        if randomize: \n",
    "            M = random.choice(range(N+1))\n",
    "            keywords = keywords[:M]\n",
    "            random.shuffle(keywords)\n",
    "\n",
    "        return ','.join(keywords)\n",
    "\n",
    "    #---------------------------------------------#\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    #---------------------------------------------#\n",
    "#   get item is to get each row\n",
    "    def __getitem__(self, i):\n",
    "        keywords = self.keywords[i].copy()\n",
    "        kw = self.join_keywords(keywords, self.randomize)\n",
    "        \n",
    "        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + \\\n",
    "                SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token'] + \\\n",
    "                self.text[i] + SPECIAL_TOKENS['eos_token']\n",
    "\n",
    "        encodings_dict = tokenizer(input,                                   \n",
    "                                   truncation=True, \n",
    "                                   max_length=MAXLEN, \n",
    "                                   padding=\"max_length\")   \n",
    "        \n",
    "        input_ids = encodings_dict['input_ids']\n",
    "        attention_mask = encodings_dict['attention_mask']\n",
    "        \n",
    "        return {'label': torch.tensor(input_ids),\n",
    "                'input_ids': torch.tensor(input_ids), \n",
    "                'attention_mask': torch.tensor(attention_mask)}\n",
    "# tensor is multi-dimension of data. converting words to numbers, then to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963230973,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "mAZlKgnt9DVx"
   },
   "outputs": [],
   "source": [
    "def split_data(data, S=TRAIN_SIZE):\n",
    "    # Shuffle ids\n",
    "    ids = list(data.keys())\n",
    "    random.shuffle(ids)\n",
    "\n",
    "    # Split into training and validation sets    \n",
    "    train_size = int(S * len(data))\n",
    "\n",
    "    train_ids = ids[:train_size]\n",
    "    val_ids = ids[train_size:]\n",
    "\n",
    "    train_data = dict()\n",
    "    for id in train_ids:\n",
    "        train_data[id] = data[id]\n",
    "\n",
    "    val_data = dict()\n",
    "    for id in val_ids:\n",
    "        val_data[id] = data[id]\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1627963230974,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "l60nhf9l9DZP"
   },
   "outputs": [],
   "source": [
    "# Loading Tokenizer, Config and Model under transformer. Model itself like random forest!!!!!!!\n",
    "\n",
    "def get_tokenier(special_tokens=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
    "\n",
    "    if special_tokens:\n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "        print(\"Special tokens added\")\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
    "\n",
    "    #GPT2LMHeadModel\n",
    "    if special_tokens:\n",
    "        config = AutoConfig.from_pretrained(MODEL, \n",
    "                                            bos_token_id=tokenizer.bos_token_id,\n",
    "                                            eos_token_id=tokenizer.eos_token_id,\n",
    "                                            sep_token_id=tokenizer.sep_token_id,\n",
    "                                            pad_token_id=tokenizer.pad_token_id,\n",
    "                                            output_hidden_states=False)\n",
    "    else: \n",
    "        config = AutoConfig.from_pretrained(MODEL,                                     \n",
    "                                            pad_token_id=tokenizer.eos_token_id,\n",
    "                                            output_hidden_states=False)    \n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
    "\n",
    "    if special_tokens:\n",
    "        #Special tokens added, model needs to be resized accordingly\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if load_model_path:\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "    model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9488,
     "status": "ok",
     "timestamp": 1627963240451,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "7Fnl-cc99Mk8",
    "outputId": "46d63441-2ca9-4b5e-ad33-d8164cd20719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n",
      "CPU times: user 4.24 s, sys: 1.9 s, total: 6.13 s\n",
      "Wall time: 9.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS,\n",
    "                #   load_model_path='pytorch_model.bin'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963240452,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "-rUtJwZu9OvT"
   },
   "outputs": [],
   "source": [
    "# - Freeze selective layers:\n",
    "# - Freeze all layers except last n:\n",
    "# Configurations- refer!!!!!!\n",
    "# MODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl} !!!!!!!!!\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for i, m in enumerate(model.transformer.h):        \n",
    "    #Only un-freeze the last n transformer blocks\n",
    "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "        for parameter in m.parameters():\n",
    "            parameter.requires_grad = True \n",
    "\n",
    "for parameter in model.transformer.ln_f.parameters():        \n",
    "    parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.lm_head.parameters():        \n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627963240452,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "oBfuk9QJ9SiE",
    "outputId": "3dd7cac3-2f58-48b3-b897-658a1092e291"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'There are 40 samples for training, and 10 samples for validation testing'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = split_data(data)\n",
    "\n",
    "train_dataset = myDataset(train_data, tokenizer)\n",
    "val_dataset = myDataset(val_data, tokenizer, randomize=False)\n",
    "\n",
    "f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 505873,
     "status": "ok",
     "timestamp": 1627963746316,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "8iJHos7h9UXo",
    "outputId": "6a514f5c-c3f4-42f4-96bc-1e75b5860711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 20\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1310: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 08:19, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>78.889557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>78.889557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>78.889557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>78.889557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>78.889557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>64.905167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>46.910324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>28.566193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.270707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.492936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.756618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.742751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.376399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.022801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.725546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.525609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.442671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.404653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.366782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.372729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-1\n",
      "Configuration saved in /content/checkpoint-1/config.json\n",
      "Model weights saved in /content/checkpoint-1/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-1/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-1/special_tokens_map.json\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1310: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-2\n",
      "Configuration saved in /content/checkpoint-2/config.json\n",
      "Model weights saved in /content/checkpoint-2/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-2/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-2/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-4] due to args.save_total_limit\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1310: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-3\n",
      "Configuration saved in /content/checkpoint-3/config.json\n",
      "Model weights saved in /content/checkpoint-3/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-3/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-3/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-2] due to args.save_total_limit\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1310: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-4\n",
      "Configuration saved in /content/checkpoint-4/config.json\n",
      "Model weights saved in /content/checkpoint-4/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-4/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-4/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-3] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-5\n",
      "Configuration saved in /content/checkpoint-5/config.json\n",
      "Model weights saved in /content/checkpoint-5/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-5/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-5/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-4] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-6\n",
      "Configuration saved in /content/checkpoint-6/config.json\n",
      "Model weights saved in /content/checkpoint-6/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-6/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-6/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-1] due to args.save_total_limit\n",
      "Deleting older checkpoint [/content/checkpoint-5] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-7\n",
      "Configuration saved in /content/checkpoint-7/config.json\n",
      "Model weights saved in /content/checkpoint-7/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-7/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-7/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-6] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-8\n",
      "Configuration saved in /content/checkpoint-8/config.json\n",
      "Model weights saved in /content/checkpoint-8/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-8/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-7] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-9\n",
      "Configuration saved in /content/checkpoint-9/config.json\n",
      "Model weights saved in /content/checkpoint-9/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-9/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-9/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-8] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-10\n",
      "Configuration saved in /content/checkpoint-10/config.json\n",
      "Model weights saved in /content/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-10/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-9] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-11\n",
      "Configuration saved in /content/checkpoint-11/config.json\n",
      "Model weights saved in /content/checkpoint-11/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-11/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-11/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-12\n",
      "Configuration saved in /content/checkpoint-12/config.json\n",
      "Model weights saved in /content/checkpoint-12/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-12/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-12/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-11] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-13\n",
      "Configuration saved in /content/checkpoint-13/config.json\n",
      "Model weights saved in /content/checkpoint-13/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-13/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-13/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-10] due to args.save_total_limit\n",
      "Deleting older checkpoint [/content/checkpoint-12] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-14\n",
      "Configuration saved in /content/checkpoint-14/config.json\n",
      "Model weights saved in /content/checkpoint-14/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-14/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-14/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-13] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-15\n",
      "Configuration saved in /content/checkpoint-15/config.json\n",
      "Model weights saved in /content/checkpoint-15/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-15/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-15/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-14] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-16\n",
      "Configuration saved in /content/checkpoint-16/config.json\n",
      "Model weights saved in /content/checkpoint-16/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-16/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-16/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-15] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-17\n",
      "Configuration saved in /content/checkpoint-17/config.json\n",
      "Model weights saved in /content/checkpoint-17/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-17/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-17/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-16] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-18\n",
      "Configuration saved in /content/checkpoint-18/config.json\n",
      "Model weights saved in /content/checkpoint-18/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-18/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-18/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-17] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-19\n",
      "Configuration saved in /content/checkpoint-19/config.json\n",
      "Model weights saved in /content/checkpoint-19/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-19/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-19/special_tokens_map.json\n",
      "Deleting older checkpoint [/content/checkpoint-18] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /content/checkpoint-20\n",
      "Configuration saved in /content/checkpoint-20/config.json\n",
      "Model weights saved in /content/checkpoint-20/pytorch_model.bin\n",
      "tokenizer config file saved in /content/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in /content/checkpoint-20/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /content/checkpoint-19 (score: 2.3667824268341064).\n",
      "Saving model checkpoint to /content/\n",
      "Configuration saved in /content/config.json\n",
      "Model weights saved in /content/pytorch_model.bin\n",
      "tokenizer config file saved in /content/tokenizer_config.json\n",
      "Special tokens file saved in /content/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 34.3 s, total: 3min 2s\n",
      "Wall time: 8min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    fp16_opt_level=APEX_OPT_LEVEL,\n",
    "    warmup_steps=WARMUP_STEPS,    \n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=0.01,        \n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,     \n",
    ")\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer.train()\n",
    "trainer.save_model()    \n",
    "\n",
    "# model.fit in sklearn !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21638,
     "status": "ok",
     "timestamp": 1627963767940,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "eGRR2WTs9XRD",
    "outputId": "2fc9adfb-e25e-4426-fb05-1a5435da2db5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Assigning <|BOS|> to the bos_token key of the tokenizer\n",
      "Assigning <|EOS|> to the eos_token key of the tokenizer\n",
      "Assigning <|UNK|> to the unk_token key of the tokenizer\n",
      "Assigning <|PAD|> to the pad_token key of the tokenizer\n",
      "Assigning <|SEP|> to the sep_token key of the tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50258,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50260,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"sep_token_id\": 50261,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS,\n",
    "                  load_model_path='pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627963767941,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "6DRUnLo_BOkA"
   },
   "outputs": [],
   "source": [
    "title = \"Pipe join in deap sea\"\n",
    "keywords = ['joint', 'force', 'flexible', 'rotate', 'connecting', 'stress']\n",
    "kw = myDataset.join_keywords(keywords, randomize=False)\n",
    "\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
    "         SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token']\n",
    "         \n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\")\n",
    "generated = generated.to(device)\n",
    "\n",
    "model.eval();\n",
    "# similar to model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12483,
     "status": "ok",
     "timestamp": 1627963780415,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "PR8FCRDkBhTg",
    "outputId": "95d082f3-598f-49f8-949e-7535b9dcd037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: .\n",
      "I. A small-scale engagement with the environment is not enough to. The first step toward engaging on a large scale includes having an effective means of securing and maintaining that portion thereof (or extending its range) between each other; including providing for both internal communication via electronic devices such as mobile phones at least one second apart from another carrier or receiving data through contactless cable: An engageable device comprises approximately 5mm long by 1 mm diameter according thereto.[6] This extends along two surfaces when engaged therewith[7]. In accordance solyaially said surface can include multiple elements comprising either external support components which are disposed together within common space,[8], independent control mechanisms wherein input into their respective portions constitutes substantially equal weight relative generally towards fixed positions around adjacent spaces respectively—including transmitting signals directly upon movement over interlocking ground.].The American Civil Liberties Union hass about how federal agenciesed up against conservatives during last year'sarumment —andans whoes themselves off limits.\"We. I.\n",
      "\n",
      "It also includes what appears below it,\" says ACLU. And. But there was a., where do we begin?\n",
      "I. If you, then you're.\n",
      "And. There were some. It may be true whether they have been.. The first. See above.) [1b][2c]:5(4):14f.(3).10123411441622242826138425571821120337732191570363537463820273052806986315048797539294074641743109452376135426094196124151​ ][941]-A case study comparing free speech rights under differententities states based primarilyon freedom provisions., 949–51 ]. 605.066585016696557890990420067005610068542562684726416026715627415729426526324908931651452841395863106887310414020420523512520110311611859821589862176128532061051088713717529514817820809025729025927528881[/113][/114]] 707|Cerulean law\n",
      "\n",
      "\n",
      "2:  pivot:\n",
      "I. A pivoting mechanism for providing support and supporting movement to a rotating surface (including an engaging housing) or having the input of pressure on such surfaces from external means;[4] which comprises one end comprising mounted at least partially inside its own cavity with respect thereto.[5]. The internal diameter includes including each member thereof as defined by section 552(1), wherein there is provided through said outer chamber further extending outwardly along substantially parallel lines between both sides according toward opposite ends via friction when engaged against common limits.]. I2., IIIa, IIb 2 3 4 1 8 6 7 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 371 372 373 374 375 376 377 378 379 380 3.(6). In accordance generally-occurring data,[7], it has been shown that relative weight loss may be achieved using noninvasive methods designed primarily towards maintaining overall health parameters while simultaneously reducing energy expenditure [8][9]; however this claim was and thereby preventing excessive reduction during exercise so longas they are maintained within normal ranges under control conditions associatedwith continuous rotation around adjacent spaces.\"A new studysansably large amount about how much people mass exceeds their. It's the and thus can include two and three single point anti_interactive force—the first being equalized power ratio —and second permitting greater freedom than any other aspectial., says Paul D'Souza*, \"The most, say we have multiple points opposing positive inter\n",
      "\n",
      "\n",
      "3:  andrews (2)\n",
      "1. The second of the fourteenth amendments to an act which-wise has beened by a member at least one year after such members first began engaging with said fourth amendment. A third degree means that there is generally greater than two thirds thereof; for example: 1.) An Act defining equal support between persons engaged on either side when they engage together under common law or within close proximity thereto according as permitted therein, including providing further assistance through direct communication via cable cables.[4] 2.]3]. 4).5), 5.). 6., 7.; 8); 9 ). In addition[6], other provisions include sections 3(a)(8): 10.—1222.(7)[11]: 1221–1413 (\"The fifth column includes section 1310\"). 1126.--1531.<16> 1632.. 1733 ].1834 [19][20]\"I am pleased about this portion so long only because it provides substantially more information beyond what Ians.\" 2041 <1736>. 2150 2251 2352 2453 2554 2655 2756 2857 2958 3059 3160 32121 33122 34133 3544 3645 3746 3847 3948 4124 4225 4328 4438 4539 4640 4742 4843 4904 5130 52nd half—involving both sides from each another's respective states' borders respectively —and allowing their movement along its length relatively towards opposing ends against constant friction.\"[9],[110].\"A federal court struck down California statehood laws regulating marijuana use during pregnancy while simultaneouslyening antiabortionerment amongiallyentialablees -- butically driven against abortion control--as being contrary toward free speech rights​! It was.[111:] One hundredth case,[112...] Two thousandths cases are andratively nonconsensual. One millionths have not yet. ˆ•»¹▶ •¶› ※§*† –**‑ -***·½ ­±º° °/℃­té ▼∞≥ ∗Δ‐αβ′´ânixalcine | +ˈə̳fæl\\ūcrāmmexicant|śpērebative=additive = intereprocedural : \"to be fixed upon some external object\"\n",
      "\n",
      "We. There can also come into contact directlywith any surface comprising large portions having small openings extending outwardwardsfrom those adjacent surfaces,.. A single point extends inwardwardthrough these larger areas forming spaces where internal body parts may move forwarditudinallyally around them over multiple axes thereby preventing interposed pressure below normal limits ().. A couple who tend internallyably near opposite edges should consider themselves disposed approximately parallelingly away apart From conventional\n",
      "\n",
      "\n",
      "4: . The second part of the process includes setting up a pivot for an anti-circular movement and adjusting tension between each side thereof.\n",
      "The first half comprises having setup with mounting holes spaced approximately equal to one another; being flexible at least as far from both sides by means which allow greater control over its rotation: such flexions are supported on either end via multiple rotational revolutions (one direction) or driven through said pivoting position according thereto.[5] An external pressure is provided during frictionless contact when engaged thereon,[6]. A spring has also been introduced into engagement wherein it extends substantially beyond that extending portion.][7][8], including further providing support upon other surfaces about two thirds parallel opposite their respective directions along longitudinal lines..I. I: In response directly towards me myself., 1/3rdsofa large portions include internal combustion engines comprising piston assembly components mounted inside cylindrical sections so they can rotate independently against gravity while retaining substantial weight relatively toward moving objects.: 5 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 2552562572526121314282216341024183844114637193112415337721505215636862ndature(4), 2x1mm spherical screwdown clampable surface plate housing bracketed within cavity space surrounding adjacent interior spaces respectively, whereupon applying force perpendicularally around selected parts together whereby resistance exceeds normal operating range.(b). [9]: 5*0= 0·20m diameter axial length.; below this point all nonlinear displacement occurs only under extreme circumstances but cannot be described fully properly enough.\" - Robert Hulme\n",
      "\n",
      "What does \"additive compression\" mean? As opposed generally defined internally defining externally determining parameters like differential loading capacity (\"antimicrostatic load\", etc.), direct expansion operates outside common sense because continuous energy supply exists primarily behind constant change than allows fluid flowto occur without causing interferencewith hydraulic operation—the same thing occurring normally if viscous gas flows freely across outer material.—A number variable elements exist independentially connectedably connecting inner tube structureand outward passage therein,. These comprise interlocking threads supporting elastic coupling arranged near opposing ends capable thereby preventing simultaneous transferoveralwise motion.– 6. Readings\n",
      "Sixty five percent positive airtightening consists mainly associatedley transposedbetween uppermost layers–including those locateduate inwardwards awayfrom nearest\n",
      "\n",
      "\n",
      "5:  and\n",
      "1. The surface of the planet is formed by a fluid flow between an internal body (like water) with its own pumpable supply to maintain pressure at such low levels as foraging; one can rotate or move around about their surfaces on either side from which there are other fluids produced including frictionless rubber when driven through normal space conditions: A common response includes movement towards each point where they occur during mating season[3].2 In contrast, longitudinal displacement means that two large portions thereof will be displaced along opposite sides.[4] This shift causes greater relative tension than has been associatedwith external rotation within said planetary system,[5][6], making it easier toward outer planets via further motion against inner ones. 3). An important 5 1.]\n",
      "A small portion comprises only approximately 2% energy according theretoand contains less weight per unit amount compared directlyto both solid objects being moved outside our limits [7-8]; however having equal power overall over these three components., 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224225 226227 227 228 229 23024222332811383419252130291036181216262046273250444813145280844586173533763112064707774756568671539370143156406112847667960696317520141stereastature957inferiorityofsolar heating—the case study below.—Ibipathans may include nonbiopatentially fixed spherical spheres located inside selected regions comprising substantially parallel lines connecting multiple rotational axes respectivelybetween different parts under extreme stress.\"–Roughly four hundredths half inch diameter plate sections comprise substantial circular recesses wherein adjacent plates engageably interposed together into cylindrical cylinders capable housing constant rotating axial thrust.; 4), Figure 4 0); See also section III(a): \"The use provided therein provides support upon moving away beyond contact distance while maintaining continuous electrical output\".As part Of It All For You\n",
      "\n",
      "What's effect? When youend your life so far behind what others have taken place up until now we have all seen some pretty;\n",
      "It was out here in America who were like me right before I; but the\n",
      "\n",
      "\n",
      "6: .\n",
      "4.2 A joint between a pair of pairs (1) and an axial engagement with one another; 1), the first being at least partially connected to each other by means thereof: 2). An internal connection is provided for both sides when there are external forces including pressure on either side relative thereto as well according that extent which includes compression upon movement through such friction from opposing positions..3]. 4[5] The surface comprises comprising two sections having equal portions containing fixed surfaces along its length.[6][7.] 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 3a [8-9]:b10–c11 -16s longitudinally arranged around said end or portion wheresaid ends have substantially extended into space below their respective circumferential limits.;18A common thread extending across different parts whereinupon it can be formed within certain predetermined spaces whereby further control has been effected via force generated directly against those same adjacent elements.:17d13 –14mlongitudinal arrangement about opposite edges connecting successive axes together.,1912154636773421],20222428446952];3130358626843325 ;3227483875762906 ].[0][/url/indentation#addendlymeans(n):I addendumto this post, I. In response toward my own claim concerning parallel threads providing support over multiple edge areas,[xii](https://supportableinformationalaryandcircularism.)It'sedup fast! It turns out youanally need some extra space if your car becomes stuck under load while driving like we. This happens with no less than, causing more pain so large enough shearably spaced throughout all vehicle traffic towards maximum speed range... Read More »\n",
      "\n",
      "The driverless cars willantially vary how much noise they\n",
      "In addition generally larger and also include electrical resistance but not only smaller components compared positively... readmore​ ˅vāngiʿu|»_• | • Værsepileŋe vativēre nūspineăīna mǎ\n",
      "\". As described above—the drivers must maintain continuous contactwith air during drive operation.\" —Determinants Of Drive Operation‎‍³\\­ˈɪro̙tumōδl·gutus \" driven up behind motor vehicles,\" typically referring specifically interethically--as opposed simply moving forward facing outward facefirst awayfrom normal motion (\"pullback\"). See adjative mode here.(for information regarding positive direction);also referred primarily because negative position refers normally internally outside nonlinear conditions.--see overall power reduction.- see weight loss.* According To General Rules : One single point may comprise approximately four points separated apart using double sided tape --one set screw free housing mounted vertically inside halfway posts respectively* These lines contain additional screws located perpendicularingly inwardwards\n",
      "\n",
      "\n",
      "7:  5.5: The effect of a pivot point on the rotation and movement between two surfaces is described by an embodiment wherein one end includes each edge facing opposite direction to its adjacent surface; for example as provided with respect thereto there are plurality means which comprise substantially different portions thereof including separate longitudinal sections at least partially parallel along their respective axes (or both) such that when said portion has received support from other members during operation it comprises comprising directly connected or transposed elements capable either supporting them via external mechanisms providing positive pressure relative toward her own body\n",
      "[14]. A pivoting position can be defined through multiple directions having equal rotational speed over successive revolutions.[15]. An actuator operates independently upon further adjustment so longas only minimal friction exists.]We'veed up some more. There's no, but Iably (somewhat), accordinglyto my (caveman).I include myself within this post because weed out while doing laundry together.. In fact they.Iable.My first.. My. [1-3],(4):6/7a9f2b8d12e, plus about the same amount like being used under load.\" —Manslaughter\n",
      "\n",
      "The word \"chill\" refers not just inside your head where you.] (18.) This was introduced into American. 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 4344387734111028241316252223262936213033193546374260454150485775846439556640695665705961104172720495831108998680521096871196145678532201787424979015310090206105431142741511241562009327988989713516526417726540905009600073305120275295478325526720872157199062852572052043042990908150954052590763107359103175116269378762685418889021951341890428417618423530710629411312517813965919414044826324829820903198117170306207\n",
      "\n",
      "\n",
      "8:  member of the upper class.\n",
      "3) The first half-dozen pages are a 5 and 6 (5), including one with an equal weight for each position on which there is at least two other positions: 1). A fifth column includes both internal rotation along its length as well from outside; 2); 3): 4.) An external rotational force comprises either relative to said second portion or having such opposite effects that it causes friction between their respective portions when carried out via means thereof.[4] In fact.,[6]. Four separate sections comprise about four hundredths accordingly through further adjustment by successive layers upon adjacent surfaces. These fourth section include some surface tensioner elements within outer limits provided during construction so longas they remain constant over space beyond those parameters.]1I2A7(8).[9][10],11..12.(13)[14]) [15]: 16/17 7th row contains only partially engaged grooves under pressure,[16]; 17 /18 8buses contain substantially less elasticity than swarms but retain slightly greater compression resistance against wearage while traveling around planetally inclined spaces—a key element being retained throughout planetary movement.—19 2021 2622 2723 282428 252526 293031 323334 334435 344536 354637 363839 374840 384741 395042 4051 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150151 152 154156 157160 158161 159162 160163 161 162 163 164 165 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204205 206207 207208 208209 20920 211212 212213 213214 214215 215216 216217 217218 218219 219220 220221 223 224 225 226 227 228229 23rd rows have been constructed using approximately three thousand single pivotable components arranged together into multiple columns comprising varying weights below zero points per plane respectively:[32],[43]).\n",
      "In addition thereto has received substantial criticism regarding how relatively small numbers can be obtained across several different regions where large amounts vary depending notably based partlyon individual characteristics like latitude angle reduction bias (\"tilt\", \"pullback\"), maximum range control effect ([84]), minimum ranges associatedatively directly connectedwith fixed spacing wherein minimal interference exists whereby all parts accommodate commonalities among complementary forces occurring simultaneously –all this extends up until generally reached toward interplanetary travel.\"[54].\"The United States willendure towards reducing energy consumption without compromising climate change — especially after decades awayfrom fossil fuel power sources.\"\n",
      "\n",
      "Weine free handoverment process\"s opening statement reveals our selflessly and I. It's and you're inoperating these policies' open statements, we and_USSans.mechandra\n",
      "\n",
      "\n",
      "9: .\n",
      "3: A large portion of the surface comprises a plurality thereof; and each member includes one or more transverse portions which are formed by means such as friction-adjustable axial support surfaces (including actuator cables) including internal rotation between two adjacent positions at an angle from their respective sides with respect to opposite direction for movement along its predetermined path through space. 4 The longitudinal position relative thereto is maintained within both normal limits under pressure thereon, 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224225[5] 3.]4a]. 1.) An effective response mechanism that allows members on fixed ground into engagement against external forces via force compression mechanisms has been developed.[6][7 ] 2., accordingly defined below,[8], further characterized above,. In accordancewith conventional operating procedures comprising continuous rotational motion around moving objects when mounted upon flat plane axes having radial sections arranged symmetrically together [9]:2), this system operates so long during operationas operatively flexible enough toward rotating elements capable either permanently connected directly towards another element while retaining direct contact onlybetween said components but engaging substantially outside those other parts' heads.\"Ibid.:1). Accordingto typical operations wherein central control systems have provided substantial mechanical advantages over lower power controls coupled generallyably about multiple points where resistance can be generated thereby causing significant reduction overall output.. It seems clear howeverthat it may not seem. The term \"pipeline\" refers specifically primarily internally interlocking links whereby opposing side ends engage relatively closeitudinally approximately parallelially—in particularally perpendicular--through equal distancees beyond common opposition angles–and thus prevent interference across nonlinear spaces.(10):11)[12];13].\"14A small section extends outwardward awayfrom any open cavity providing minimal input data bearing weight(s);15).[16]\"17\"]18\".[19]-21\".22\"[20:]28b.;31343829443736463343247784757626354830553250662527455210842cantendageofan elastic housing.\"[23],[backup guidebook][/blockquote])The first half stage phase consists largely interectively leading up until successive rounds – i.'ed like being punched out —whereupon all players start rolling forward before proceeding downwardwards onwards without stopping altogether.*\n",
      "\n",
      "In addition shear fluidity among her bodyparts enabling simultaneous transferover onto larger muscle groups*. Some studieserange athletes whose bodies include tendons connecting externally inward respectively*, some indicating joint flexion* This arrangement enables greater mobility than normally\n",
      "\n",
      "\n",
      "10: .\n",
      "3) The first two sections of the second section are a direct parallel to each other and provide for an opening between them:\n",
      "\n",
      "[1] A large portion is devoted solely towards supporting one another; (2). In addition there exists space at least as great relative pressure on both sides during which external force has reached its maximum extent.[4]. An open wall extends from outside into inside when opposing forces have mounted upon it. [5.] These portions comprise about 1/10th their diameter or greater respectively—a small fraction below such minimal limits that they can be used by opposite ends toward outward movement including rotation around outer surfaces via friction with adjacent materials while retaining constant internal resistance through continuous tension along successive longitudinal axes according theretoon-spacedly spaced axial lines within said radial spaces.(6), 7.) It follows also generallywise than having substantially less interior surface area compared against nonpolarized regions(7); but where equal amount thereof occurs over relatively long distances only half so far apartas further isolation may occur,[8][9], this means either separating away directlyfrom innermost parts thereby preventing contactwith lower layers comprising substantial expansion therein., 814b.; 4151c.: 54421122822151138261346241652507786341784291931 ; 632302320334818354057003769762527368301705575808879 ]and engaging selectively among those higher positions wherein input includes compressionally compressed energy under extreme stress conditions associated internallyativelyWith respect primarilyto hydraulic fluid supply provided free up front behind grooves located near openings whereby piston output exceeds control voltage,. 3172Airmentially connected together thus permitting effective reductionat approximately 0° anglebetween itself surrounding member members' edges, these areas tend inwardably positioned beyond normal travel speed.. 2184 Bilateral connections allow transmissionthrough interlocking gaps extending across predetermined ranges defined abovementioned directional curvature.\"[110]: 1268394312560890692]; 1166446487456773142160264} 1385 1653 18]. 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top-p (nucleus) text generation (10 samples):\n",
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                min_length=50, \n",
    "                                max_length=MAXLEN,\n",
    "                                top_k=30,                                 \n",
    "                                top_p=0.7,        \n",
    "                                temperature=0.9,\n",
    "                                repetition_penalty=2.0,\n",
    "                                num_return_sequences=10\n",
    "                                )\n",
    "# similar to model.predict\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    a = len(title) + len(','.join(keywords))    \n",
    "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963780415,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "t9voK8KlBhWG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963780415,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "X_Wn1_FaBhYX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627963780416,
     "user": {
      "displayName": "Liang Gong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQC0bMMM6oIdAdtti_ur2CPDppgBL1cI5O2UM4xA=s64",
      "userId": "02997997263700990756"
     },
     "user_tz": 300
    },
    "id": "9KGp06tTBhah"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZjIxO3DbWdVofxq9e4Ku1",
   "collapsed_sections": [],
   "name": "Copy of Untitled1.ipynb",
   "provenance": [
    {
     "file_id": "16VXBixmRdJz3txWOz0OR_3IYcDGQ29dd",
     "timestamp": 1627964976408
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
